{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878310e2",
   "metadata": {},
   "source": [
    "### Essaymaker Agent flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c5a90",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082c53f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv('/Users/felipe_q/Desktop/AI_models/Agents/agent_venv/Agent_Development/langraph/credentials.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35a38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c5b866",
   "metadata": {},
   "source": [
    "### Initialize Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac16ef",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "\n",
    "    task: str #Human Input.\n",
    "    plan: str #This will be generated by the planning Agent\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str] # List of documents that Tavily has researched about.\n",
    "    revision_number: int #Keepo track of the revisions we have made.\n",
    "    max_revisions: int #Criteria wheter to stop or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06ccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69826986",
   "metadata": {},
   "source": [
    "### We define the prompts - Each prompt is designed to create different Agents. 1 prompt = 1 Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ca842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\"\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to make sure we are getting a list of strings from the language model\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel #Represents the results that we want to get back from the model.\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str] #In this case is a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Tavily Client\n",
    "from tavily import TavilyClient\n",
    "tavily = TavilyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec246f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize with the planning agent.\n",
    "\n",
    "def plan_node(state: AgentState):\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content = PLAN_PROMPT),\n",
    "        HumanMessage(content = state['task'])] #The task that we want to do.\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {'plan': response.content} #We update the plan based on the output of the LLM.\n",
    "    \n",
    "\n",
    "#The following function takes the plan of the previous functions and we do some research based on that output\n",
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content = RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content = state['task'])\n",
    "    ])\n",
    "\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query = q, max_results =2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    \n",
    "    return {'content': content}\n",
    "    \n",
    "# Based on the research made in the previous function, we will be generating the first draft.\n",
    "\n",
    "\n",
    "def generation_node(state: AgentState):\n",
    "    \n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content = f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content = WRITER_PROMPT.format(content = content)\n",
    "        ),\n",
    "        user_message]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {'draft': response.content, 'revision_number': state.get('revision_number',1)+1}\n",
    "\n",
    "def reflection_node(state: AgentState):\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content = REFLECTION_PROMPT),\n",
    "        HumanMessage(content = state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {'critique': response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8a1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28e5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
